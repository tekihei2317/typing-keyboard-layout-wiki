# ブリ中トロ配列の指標の計算方法

[左右対称型キーボード専用かな配列「ブリ中トロ配列」 - Wisteria::Diary](https://mobitan.hateblo.jp/entry/2020/04/30/233245)

配列の定量評価が行われているので、どのように計算しているのかを確認してみます。

[mobitan/chutoro: ブリ中トロ配列](https://github.com/mobitan/chutoro)

リポジトリはこちら。`tools/eval-2gram.html`を読みます。

## 評価指標と計算方法

- 打鍵数（打鍵効率）
- 交互打鍵
- 同手同段異指
- 同指異鍵
- 同指跳躍

## ストロークに変換する流れ

## 読んでいく

かなをストロークに変換する部分と、指標を計算する部分に大きく分けられる。ストロークの変換は後で読むことにして、指標を計算するところから読む。

### 配列データの持ち方

```js
function evalLayouts() {
    for (var i = 0; i < layouts.length; ++i) {
        evalLayout(layouts[i], i, layouts)
    }
}
```

配列と、配列のインデックス、配列一覧を渡している。インデックスと一覧はなんで要るのかちょっと分からない。

配列は次のようなデータとして持っている。`[配列名, URL, 文字の打ち方, シフト方式, シフトキー, 同手シフトの有無]`を表す。

```js
var layouts = [
    ["ローマ字", "", [
        ["んあ", "nnあ"], ["んい", "nnい"], ["んう", "nnう"], ["んえ", "nnえ"], ["んお", "nnお"],
      ], "", "", ""
    ],
    ["新JIS配列 (X 6004)", "http://jisx6004.client.jp/jisx6004.html", [
        ["あ", "b"],     ["い", "k"],     ["う", "j"],     ["え", "Su|"],   ["お", "Sj|"],
      ], "後置", "小|小", "なし"
    ]
]
```

### evalLayoutとコーパス

`evalLayout`を読む。elementには配列が入っている。`data`はコーパスだろう。

テキストを取り出して、`elements[2]`=文字の打ち方を使ってストロークに変換している。

`strokes.replace(/:R/g, 'X')`のところは何やっているのだろうと思ったが、TRONのメタ記号をXに置換してから全部消しているらしい。他の配列では関係ないので読み飛ばそう。

`data`に何が入っているのかを読んでいく。

```js
function evalLayout(element, index, array) {
    for (var text in data) {
        var count = data[text]
        var strokes = text
        element[2].forEach(function(element, index, array) {
            strokes = strokes.replace(new RegExp(element[0], 'g'), element[1])
        })
        strokes = strokes.replace(/:R/g, 'X')
        strokes = strokes.replace(/\|L/g, 'X')
        strokes = strokes.replace(/\|S/g, 'X')
        strokes = strokes.replace(/[:\|X]/g, '')
        strokeLength += strokes.length * count
        textLength += text.length * count
    }
}
```

おそらくここだろう。`#text`は`<textarea>`で、連接データを編集できるようにこうなっている。

```js
var data = {} // {text: frequency}
var dataLength = 0

function loadData() {
    data = {}
    var lines = document.getElementById('text').value.split("\n")
    for (var i = 0; i < lines.length; ++i) {
      // 省略
    }
}
```

連接データは結構不思議な形式で、何gramのデータなのかよく分からない。

頻度と単語の間はタブ、単語は空白で区切られている。`8104<tab>て<space>い`みたいな感じ。

> 京都大学 学術情報メディアセンター 大規模テキストアーカイブ研究分野 のウェブサイトで配布されている、BCCWJ（コアデータ）コーパスから生成された仮名漢字変換用 2-gram の上位1万語彙を用いて評価した

とあるが、制限があるのかリンク切れかで確認することはできない。

```
26423	。
8104	て い
7177	た 。
7170	し て
6199	し た
5810	っ て
5288	い る
5258	は 、
5119	る 。
...
916	よう に
890	あ っ
890	）
875	ま せ
875	な く
871	てき な
869	だっ た
867	の は
864	しょ う
853	かっ た
846	い の
...
572	く 、
561	へいせい じゅう
561	を し
557	た い
549	う こと
546	な り
539	ろ う
528	に かん
528	ため 、
528	おけ る
526	に おけ
```

処理の中身を読んでいく。

行をタブ区切りで分割する。length=0とlength=1のところはデータが不正なので無視していいだろう。

次に、単語から`、`、` `、`-`、`」`の4つを削除して連結している。`ァ`~`ヶ`はひらがなに変換している。

```js
function loadData() {
    data = {}
    var lines = document.getElementById('text').value.split("\n")
    for (var i = 0; i < lines.length; ++i) {
        if (!lines[i]) continue
        var tmp = lines[i].split(/\t/)
        if (tmp.length < 1) continue
        if (tmp.length < 2) {
            var freq = 1
            var text = tmp[0]
        } else {
            var freq = parseInt(tmp[0])
            var text = tmp[1]
        }
        text = text.replace(/[^、-ヿ]/g, '') // 単語を連結する。
        // 2-gramには単語が2回ずつ現れるので、単語間の連接の重みが半分になるが、よしとする
        text = text.replace(/[ァ-ヶ]/g, function(s) {
            return String.fromCharCode(s.charCodeAt(0) - 0x60);
        })
        if (!data[text]) data[text] = 0
        data[text] += freq
        dataLength += 1
        // console.log('"' + text + '" = ' + freq + '')
    }
}
```

コメントの「2-gramには単語が2回ずつ現れるので、単語間の連接の重みが半分になるが、よしとする」については、重要な部分だと思われるので最後に整理した。

### evalLayoutに戻る

#### 交互打鍵の計算

指標を計算している部分。コメントで指標ごとに区切られているので1つずつ読んでいく。

```js
// left/right
var lr = strokes.replace(/[SLR]/g, '')
lr = lr.replace(/[12345qwertasdfgzxcvb\[\]]/g, 'L')
lr = lr.replace(/[67890yuiop\-=hjkl;''\\nm,\.\/]/g, 'R')
if (m = lr.match(/L/g)) lCount += m.length * count
if (m = lr.match(/R/g)) rCount += m.length * count
if (m = lr.match(/LR/g)) lrCount += m.length * count
if (m = lr.match(/RL/g)) rlCount += m.length * count
lrLength += lr.length * count
```

左手の文字をL、右手の文字をRに置換してから、テキストに含まれるL、R、LR、RLの個数をそれぞれ数えている。

`lrLength += lr.length * count`だが、2-gramの個数を数えているんだったら`(lr.length - 1) * count`が正しいだろう。

ループを抜けて、集計している部分を見てみる。`(LRとRLの個数) / lrLength`で計算している。やはり分母が少し大きく見積もられている。

```js
inner += '<td>' + (lrCount + rlCount).toLocaleString() + ' (' + ((lrCount + rlCount) / lrLength * 100).toFixed(1) + '%)</td>'
```

#### 同手同段異指の計算

もう一箇所だけ読んでみる。`同手同段異指`、いわゆるアルペジオを計算しているところ。

同じ手で同じ行を打つ場合の個数を数えている。

`sr = sr.replace(/(.)\1+/g, '$1')`は同じキーを連続で打つ場合を圧縮している。`

```js
// same row
var sr = strokes
sr = sr.replace(/(.)\1+/g, '$1')
sr = sr.replace(/[qwer]/g, 'A')
sr = sr.replace(/[asdf]/g, 'B')
sr = sr.replace(/[zxcv]/g, 'C')
sr = sr.replace(/[uiop]/g, 'D')
sr = sr.replace(/[jkl;]/g, 'E')
sr = sr.replace(/[m,\.\/]/g, 'F')
var prev = ' '
for (var i = 0; i < sr.length; ++i) {
    c = sr.charAt(i)
    if (c == prev)
        srCount += count
    prev = c
}
srLength += sr.length * count
```

```js
inner += '<td>' + srCount.toLocaleString() + ' (' + (srCount / srLength * 100).toFixed(1) + '%)</td>'
```

気になるところ

- 同鍵連続を圧縮しているので分母が小さくなり、実際より高くなる
- tyghbnの真ん中の指が変換されていなさそうなので、`et`などは数えられていない
- sr.length * countについては、先ほどと同様にsr.length - 1が適切

### かな→ストロークの変換について

既に通り過ぎているのだが、再掲。

```js
function evalLayout(element, index, array) {
    for (var text in data) {
        var count = data[text]
        var strokes = text
        element[2].forEach(function(element, index, array) {
            strokes = strokes.replace(new RegExp(element[0], 'g'), element[1])
        })
        strokes = strokes.replace(/:R/g, 'X')
        strokes = strokes.replace(/\|L/g, 'X')
        strokes = strokes.replace(/\|S/g, 'X')
        strokes = strokes.replace(/[:\|X]/g, '')
        strokeLength += strokes.length * count
        textLength += text.length * count
    }
}
```

`[テキスト, ストローク]`という要素を持った配列をループして、順番に正規表現で置換している。

各配列について、具体例で確認してみる。

#### ローマ字入力

最初に`["んあ", "nnあ"], ["んい", "nnい"],...`が定義されているので、「んの後ろに母音またはナ行が来る場合はnを2回重ねる必要がある」というルールはクリアしている。

具体的に`こんにちは`がどう変換されるか見てみよう。

定義順に

- ["んに", "nnに"]
- ["こ", "ko"]
- ["ち", "ti"]
- ["に", "ni"]
- ["は", "ha"]

なので、

```text
こんにちは
こnnにちは
konnにちは
konnにtiは
konnnitiは
konnnitiha
```

のようになる。

んの例外→拗音と外来音→清音と濁音→小書き、促音 という順番に定義されているのがポイント。

促音については

- ["っ([a-z])", "$1$1"],
- ["っ", "xtu"]

と定義されているので、大抵の場合は`っta`→`tta`のように変換される。

#### その他の配列

- 新JISやTRONはシフトを表す記号が入っている？
- ブリ中トロでは`きゅ`と`きゅう`で、`きゅ`の入力が違う
- ブリ中トロでは`です` `ます`を最初に変換している

あたりに注意が必要だろうか。オーソドックスな月系配列は、かな単位で定義しているので特に問題は起きないだろう。

### 疑問点に戻る

コメントについて、改めて考えてみよう。

```js
text = text.replace(/[^、-ヿ]/g, '') // 単語を連結する。
// 2-gramには単語が2回ずつ現れるので、単語間の連接の重みが半分になるが、よしとする
```

評価に使われているコーパスは、単語単位の2-gramデータである。

具体的に「わたしはひとです」という文章で考えてみる。これは「わたし/は/ひと/で/す」に分割され、次のような2-gramデータになる。

```text
1 わたし は
1 は ひと
1 ひと で
1 で す
```

(1) 打鍵数について

2-gramを連結して数えているので、`count(word)`で単語の打鍵数を表すとすると、上記のコーパスの打鍵数は

```
count(わたし) + 2 * {count(は) + count(ひと) + count(で)} + count(す)
```

になる。打鍵が単語の境界をまたぐ場合（ブリ中トロの「です」など）やローマ字のnnの処理で少し変わるが、大雑把にはこんな感じ。

最初と最後だけ1回しか数えていないが、これはコーパス全体の大きさを考えると誤差なので問題ないだろう。

(2) その他の評価値について

他の指標は2-gramに対して計算している。

例えば、上記のコーパスに対してローマ字の指標を計算することを考える。

```text
watasi ha
ha hito
hito de
de su
```

最初と最後の単語以外は、単語内の連節は2回数えられる。単語が2回出てくるからである。

しかし、単語と単語の間の連節、つまり「ha hito」の「ah」や、「hito de」のodは1回しか数えられない。

つまり「連節の重みが半分になる」というのは、「単語内の2連節は単語が2回出現するので2回数えられるが、単語間の連節は1回しか数えられない」ということ。

これはそこそこ大きな問題に思える、実装の都合上、許容することになったのだと思われる。

## まとめ

- 評価に使われているコーパスは、単語2-gramのデータである。
- 単語2-gramを連結したテキストに対して、かな→ストロークの変換ルールを順番に適用してストロークを得ている。
- 指標の誤差を許容している部分や、実装のミスがいくつかあるので注意が必要
  - 打鍵2-gramに対する指標は、単語間の打鍵を半分しか数えていない。上位は短い単語が多いので、影響そこそこありそうに見える。
  - 交互打鍵について
    - 分母が2-gramの個数ではなく、文字数になっている（-1していない）
  - 同段異指について
    - 交互打鍵と同様に分母の計算ミス
    - 同鍵連続を圧縮しているので、分母が小さくなっている
    - 中央列（TYGHBN）をカウントしていないことに注意が必要
  - その他の指標は未確認
